#!/usr/bin/env python3
"""
Filler Audio Processor for Pipecat v2

Sits between STT and LLM in the pipeline. When a TranscriptionFrame arrives
(user finished speaking), immediately pushes a short filler audio clip
("Hmm.", "Okay.", etc.) to the output so the user hears a thinking cue
while the LLM generates its response.

Filler clips are pre-generated by scripts/generate_filler_audio.py using
the same Kyutai TTS model and voice as the main TTS service, so the filler
voice matches the bot's voice.

Pipeline position:
  transport.input() → vad → stt → [filler] → llm → tts → transport.output()
"""

import os
import random
from pathlib import Path
from typing import Optional

import numpy as np
from loguru import logger

from pipecat.frames.frames import (
    Frame,
    TTSAudioRawFrame,
    TTSStartedFrame,
    TTSStoppedFrame,
    TranscriptionFrame,
)
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor

# =============================================================================
# Config
# =============================================================================

FILLER_AUDIO_DIR = Path(__file__).resolve().parent.parent / "filler_audio"
SAMPLE_RATE = 24000  # Must match Kyutai TTS output

# Chunk size when pushing filler audio (~100ms chunks)
CHUNK_SAMPLES = SAMPLE_RATE // 10  # 2400 samples = 100ms
CHUNK_BYTES = CHUNK_SAMPLES * 2    # int16 = 2 bytes per sample

# Minimum word count in transcription to trigger filler.
# Very short utterances ("yes", "no") get fast LLM responses anyway.
MIN_WORDS_FOR_FILLER = 3


class FillerAudioProcessor(FrameProcessor):
    """Injects a short filler audio clip when the user finishes speaking.

    On receiving a TranscriptionFrame:
    1. Picks a random pre-generated filler clip
    2. Pushes TTSStartedFrame + audio chunks + TTSStoppedFrame downstream
    3. Forwards the original TranscriptionFrame to the LLM

    The filler plays during the ~2-3s window while the LLM is thinking,
    giving the user immediate audio feedback that they were heard.
    """

    def __init__(self, *, enabled: bool = True, filler_dir: Optional[Path] = None, **kwargs):
        super().__init__(**kwargs)
        self._enabled = enabled
        self._filler_dir = filler_dir or FILLER_AUDIO_DIR
        self._clips: list[tuple[str, bytes]] = []  # (phrase, raw_pcm_bytes)
        self._loaded = False

    def _load_clips(self) -> None:
        """Load pre-generated filler audio clips from disk."""
        if self._loaded:
            return

        manifest_path = self._filler_dir / "manifest.txt"
        if not manifest_path.exists():
            logger.warning(
                f"Filler audio manifest not found at {manifest_path}. "
                "Run scripts/generate_filler_audio.py first. Filler disabled."
            )
            self._enabled = False
            self._loaded = True
            return

        clips_loaded = 0
        with open(manifest_path) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split("\t", 1)
                if len(parts) != 2:
                    continue
                filename, phrase = parts
                pcm_path = self._filler_dir / filename
                if pcm_path.exists():
                    audio_bytes = pcm_path.read_bytes()
                    if len(audio_bytes) > 0:
                        self._clips.append((phrase, audio_bytes))
                        clips_loaded += 1
                        duration_ms = len(audio_bytes) / 2 / SAMPLE_RATE * 1000
                        logger.debug(f"  Loaded filler: '{phrase}' ({duration_ms:.0f}ms)")
                    else:
                        logger.warning(f"  Empty filler clip: {filename}")
                else:
                    logger.warning(f"  Missing filler clip: {filename}")

        self._loaded = True

        if clips_loaded == 0:
            logger.warning("No filler audio clips loaded. Filler disabled.")
            self._enabled = False
        else:
            logger.info(f"Filler audio: loaded {clips_loaded} clips from {self._filler_dir}")

    async def process_frame(self, frame: Frame, direction: FrameDirection) -> None:
        """Process frames. Inject filler audio before TranscriptionFrames."""
        await super().process_frame(frame, direction)

        if not self._enabled:
            await self.push_frame(frame, direction)
            return

        # Lazy-load clips on first frame
        if not self._loaded:
            self._load_clips()

        if not self._enabled:
            # Loading failed — pass through
            await self.push_frame(frame, direction)
            return

        if isinstance(frame, TranscriptionFrame) and direction == FrameDirection.DOWNSTREAM:
            text = frame.text.strip() if frame.text else ""
            word_count = len(text.split()) if text else 0

            if word_count >= MIN_WORDS_FOR_FILLER and self._clips:
                phrase, audio_bytes = random.choice(self._clips)
                logger.debug(
                    f"Filler audio: playing '{phrase}' before LLM "
                    f"(transcription: {word_count} words)"
                )

                # Push filler audio downstream (toward output/TTS)
                await self.push_frame(TTSStartedFrame(), FrameDirection.DOWNSTREAM)

                # Push audio in chunks to avoid one giant frame
                for i in range(0, len(audio_bytes), CHUNK_BYTES):
                    chunk = audio_bytes[i : i + CHUNK_BYTES]
                    if chunk:
                        await self.push_frame(
                            TTSAudioRawFrame(
                                audio=chunk,
                                sample_rate=SAMPLE_RATE,
                                num_channels=1,
                            ),
                            FrameDirection.DOWNSTREAM,
                        )

                await self.push_frame(TTSStoppedFrame(), FrameDirection.DOWNSTREAM)
            else:
                if word_count > 0 and word_count < MIN_WORDS_FOR_FILLER:
                    logger.debug(
                        f"Filler audio: skipped (only {word_count} words, "
                        f"need {MIN_WORDS_FOR_FILLER}+)"
                    )

        # Always forward the original frame
        await self.push_frame(frame, direction)
